{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anubhav2017/Genomics_notebooks/blob/main/approach_kmer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XyizGGzTgCp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D,Reshape, LSTM, Dropout, TimeDistributed\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "bases={'A':np.array([0,0,0,1]), 'C':np.array([0,0,1,0]), 'G':np.array([0,1,0,0]), 'T':np.array([1,0,0,0])}\n",
        "\n",
        "def Kmers_funct(seq, size):\n",
        "    return [seq[x:x+size].lower() for x in range(len(seq) - size + 1)]\n",
        "\n",
        "def one_hot_encode_2(y,num_classes):\n",
        "    y_encoded=[]\n",
        "    for value in y:\n",
        "\t    letter = [0 for _ in range(num_classes)]\n",
        "\t    letter[value] = 1\n",
        "\t    y_encoded.append(letter)\n",
        "    return np.array(y_encoded,dtype=np.float16)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2A8S8tGTgCr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def selectref(el,pa,pc,pg,pt):\n",
        "\n",
        "  dicref={'U':['T'],\n",
        "  'R':['A','G'],\n",
        "  'Y':['C','T'],\n",
        "  'S':['G','C'],\n",
        "  'W':['A','T'],\n",
        "  'K':['G','T'],\n",
        "  'M':['A','C'],\n",
        "  'B':['C','G','T'],\n",
        "  'D':['A','G','T'],\n",
        "  'H':['A','C','T'],\n",
        "  'V':['A','C','G'],\n",
        "  'N':['A','T','G','C'],\n",
        "  }\n",
        "\n",
        "  dicprobs={'U':[1],\n",
        "  'R':[pa/(pa+pg),pg/(pa+pg)],\n",
        "  'Y':[pc/(pc+pt),pt/(pc+pt)],\n",
        "  'S':[pg/(pc+pg),pc/(pc+pg)],\n",
        "  'W':[pa/(pa+pt),pt/(pa+pt)],\n",
        "  'K':[pg/(pt+pg),pt/(pt+pg)],\n",
        "  'M':[pa/(pa+pc),pc/(pa+pc)],\n",
        "  'B':[pc/(pc+pg+pt),pg/(pc+pg+pt),pt/(pc+pg+pt)],\n",
        "  'D':[pa/(pa+pg+pt),pg/(pa+pg+pt),pt/(pa+pg+pt)],\n",
        "  'H':[pa/(pc+pa+pt),pc/(pc+pa+pt),pt/(pc+pa+pt)],\n",
        "  'V':[pa/(pc+pg+pa),pc/(pc+pg+pa),pg/(pc+pg+pa)],\n",
        "  'N':[pa/(pc+pg+pa+pt),pt/(pc+pg+pa+pt),pg/(pc+pg+pa+pt),pc/(pc+pg+pa+pt)]}\n",
        "\n",
        "  # print(dicprobs[el])\n",
        "  \n",
        "  return np.random.choice(dicref[el],p=dicprobs[el])\n",
        "  # return np.random.choice(dicref[el],p=dicprobs[el])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joff9qRRkLgw",
        "outputId": "8c8dc9d8-bff7-467e-bdc3-569d2bb9ff26"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !pip install BioPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLq765UoTgCs",
        "outputId": "724ca0d8-df4c-4de5-b85e-19639e903bf0"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "\n",
        "unique_elems=dict()\n",
        "\n",
        "all_sequences=[]\n",
        "\n",
        "for sequence in SeqIO.parse('ncbi_16s_18s_merged.fasta', \"fasta\"):\n",
        "    unique_elems[sequence.description.split()[1]]=0\n",
        "    seq=\"\"\n",
        "\n",
        "    base_count=dict()\n",
        "    base_count['A']=0\n",
        "    base_count['C']=0\n",
        "    base_count['G']=0\n",
        "    base_count['T']=0\n",
        "    base_count['others']=0\n",
        "\n",
        "    for el in sequence.seq:\n",
        "      if el not in base_count.keys():\n",
        "\n",
        "        base_count['others']+=1\n",
        "      else:\n",
        "        base_count[el]+=1\n",
        "    \n",
        "    na=base_count['A']\n",
        "    nc=base_count['C']\n",
        "    ng=base_count['G']\n",
        "    nt=base_count['T']\n",
        "\n",
        "    pa=float(na/(na+nc+ng+nt))\n",
        "    pc=float(nc/(na+nc+ng+nt))\n",
        "    pg=float(ng/(na+nc+ng+nt))\n",
        "    pt=float(nt/(na+nc+ng+nt))\n",
        "\n",
        "    \n",
        "    for el in sequence.seq:\n",
        "      if el not in base_count.keys():\n",
        "\n",
        "        seq += (selectref(el,pa,pc,pg,pt))\n",
        "      else:\n",
        "        seq+=el\n",
        "    \n",
        "    words = Kmers_funct(seq, size=6)\n",
        "    joined_sentence = ' '.join(words)\n",
        "    all_sequences.append(joined_sentence)\n",
        "\n",
        "X=cv.fit_transform(all_sequences).toarray()\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from Bio import SeqIO\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# cv = CountVectorizer()\n",
        "\n",
        "# unique_elems=dict()\n",
        "\n",
        "# for sequence in SeqIO.parse('ncbi_16s_18s_merged.fasta', \"fasta\"):\n",
        "#     unique_elems[sequence.description.split()[1]]=0# from Bio import SeqIO\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# cv = CountVectorizer()\n",
        "\n",
        "# unique_elems=dict()\n",
        "\n",
        "# for sequence in SeqIO.parse('ncbi_16s_18s_merged.fasta', \"fasta\"):\n",
        "#     unique_elems[sequence.description.split()[1]]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyKpX2L3TgCt"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "x_data=[]\n",
        "y_data=[]\n",
        "for el in unique_elems.keys():\n",
        "    unique_elems[el]=i\n",
        "    i+=1\n",
        "\n",
        "i=0\n",
        "for sequence in SeqIO.parse('ncbi_16s_18s_merged.fasta', \"fasta\"):\n",
        "    x_data.append(X[i])\n",
        "    y_data.append(unique_elems[sequence.description.split()[1]])\n",
        "    i+=1\n",
        "\n",
        "lm=len(unique_elems)\n",
        "\n",
        "class_count=dict()\n",
        "\n",
        "for i in range(lm):\n",
        "  class_count[i]=0\n",
        "\n",
        "for el in y_data:\n",
        "  class_count[el]+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "A9ggUdrYiJAA",
        "outputId": "e8440183-7047-4842-eb69-59c48dfd1b18"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(list(class_count.keys()), list(class_count.values()), color='g')\n",
        "plt.title(\"Number of samples corresponding to various genus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW-DLrIMjDXJ"
      },
      "outputs": [],
      "source": [
        "dominant_classes=([idx for idx, element in enumerate(class_count.values()) if element>50])\n",
        "\n",
        "\n",
        "indices_to_remove=[]\n",
        "\n",
        "for el in dominant_classes:\n",
        "  # print(list(np.where(np.array(y_data) == el))[0])\n",
        "  indices_to_remove+=random.sample(list(np.where(np.array(y_data) == el)[0]),class_count[el]-50)\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgTzJ6pO-jbl"
      },
      "outputs": [],
      "source": [
        "x_data_new=[]\n",
        "y_data_new=[]\n",
        "\n",
        "for i in range(len(y_data)):\n",
        "  if i not in indices_to_remove:\n",
        "    x_data_new.append(x_data[i])\n",
        "    y_data_new.append(y_data[i])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5tvx8tutqSI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def release_list(a):\n",
        "   del a[:]\n",
        "   del a\n",
        "\n",
        "release_list(x_data)\n",
        "release_list(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpU5_IfQRcyU"
      },
      "outputs": [],
      "source": [
        "class_count_new=dict()\n",
        "\n",
        "for i in range(lm):\n",
        "  class_count_new[i]=0\n",
        "for el in y_data_new:\n",
        "  class_count_new[el]+=1\n",
        "\n",
        "\n",
        "plt.plot(list(class_count_new.keys()), list(class_count_new.values()), color='g')\n",
        "plt.title(\"Number of samples corresponding to various genus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQX_8Nptj0gv"
      },
      "outputs": [],
      "source": [
        "desired_count=dict()\n",
        "\n",
        "for i in range(lm):\n",
        "  if class_count[i]<10:\n",
        "    desired_count[i]=10\n",
        "  else:\n",
        "    desired_count[i]=class_count[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tWv3VmQhy0m"
      },
      "outputs": [],
      "source": [
        "# from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "\n",
        "# oversample = RandomOverSampler(sampling_strategy=desired_count)\n",
        "# x,y=oversample.fit_resample(x_data_new, y_data_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYfUC1Dgs6Cu"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.bar(desired_count.keys(), desired_count.values(), color='g')\n",
        "plt.title(\"Number of samples corresponding to various genus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQvah_5ptkCJ"
      },
      "outputs": [],
      "source": [
        "x_data=x_data_new.copy()\n",
        "y_data=y_data_new.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzMYnTMqTgCu"
      },
      "outputs": [],
      "source": [
        "\n",
        "# x_train=[]\n",
        "# y_train=[]\n",
        "\n",
        "# rare_items=[]\n",
        "\n",
        "# for item in class_count.keys():\n",
        "#   if class_count[item] < 2:\n",
        "#     rare_items.append(item)\n",
        "\n",
        "# i=0\n",
        "# for el in y_data_new:\n",
        "#   if el in rare_items:\n",
        "#     x_train.append(x_data_new[i])\n",
        "#     y_train.append(el)\n",
        "\n",
        "#   i+=1\n",
        "\n",
        "\n",
        "x_data,y_data=shuffle(x_data,y_data)\n",
        "\n",
        "x_train=x_data[:int(len(x_data)*0.8)]\n",
        "y_train=y_data[:int(len(y_data)*0.8)]\n",
        "\n",
        "\n",
        "x_test=x_data[int(len(x_data)*0.8):]\n",
        "y_test=y_data[int(len(y_data)*0.8):]\n",
        "\n",
        "print(len(x_train))\n",
        "\n",
        "y_train=one_hot_encode_2(y_train,len(unique_elems))\n",
        "y_test=one_hot_encode_2(y_test,len(unique_elems))\n",
        "\n",
        "x_train=np.array(x_train,dtype=np.float32)\n",
        "x_train=np.reshape(x_train,(-1,4096,1))\n",
        "\n",
        "x_test=np.array(x_test,dtype=np.float32)\n",
        "x_test=np.reshape(x_test,(-1,4096,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghugkjLqTovx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "checkpoint_path = \"/content/drive/My Drive/training_genomics_kmer/{epoch:03d}/cp-{epoch:04d}\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpgvyARzTgCv"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add((Conv1D(filters=6, kernel_size=6, activation='relu')))\n",
        "model.add((Conv1D(filters=3, kernel_size=6, activation='relu')))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024,activation='relu'))\n",
        "model.add(Dense(units=lm, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.load_weights(\"/content/drive/My Drive/training_genomics_kmer/010/cp-0010\")\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=2, mode='min')\n",
        "\n",
        "history = model.fit(x_train[0:1], y_train[0:1], epochs=1, verbose=1)\n",
        "model.summary()\n",
        "# history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data= (x_test,y_test),callbacks=[cp_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mAdxzGQVYKjF",
        "outputId": "01ed2d5d-3bd9-4218-8909-d9a83277693e"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "preds=model.predict(x_data)\n",
        "\n",
        "y_pred_labels=[np.argmax(el) for el in preds]\n",
        "y_data_labels=[np.argmax(el) for el in y_data]\n",
        "\n",
        "print(metrics.confusion_matrix(y_data_labels, y_pred_labels))\n",
        "\n",
        "print(metrics.classification_report(y_data_labels, y_pred_labels, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3PNAaRsWokI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve,auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "thresh ={}\n",
        "roc_auc={}\n",
        "n_class = lm\n",
        "# y_true=np.array(y_true)\n",
        "preds_training_data=model.predict(x_train)\n",
        "# print(preds[0:3])\n",
        "# print(y_test[0:3])\n",
        "\n",
        "for i in range(n_class):\n",
        "  # print(y_train[:,i])\n",
        "\n",
        "  if len(np.unique(y_test[:,i]))==2:\n",
        "    fpr[i], tpr[i], thresh[i] = roc_curve(y_test[:,i], preds[:,i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnKd7ltYfYWo"
      },
      "outputs": [],
      "source": [
        "print(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yk0h8wsoy8m9"
      },
      "outputs": [],
      "source": [
        "release_list(y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8ZCMvjEs3KZ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "a=[1,2,3,4]\n",
        "b=random.sample(a,2)\n",
        "print(a)\n",
        "print(b)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "approach_kmer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8eda46fcdaf684ca6c615bf0acdae196e42139c0edab1eb57e328e85edfac349"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('genomics': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
