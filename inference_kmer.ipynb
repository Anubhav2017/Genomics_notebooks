{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anubhav2017/Genomics_notebooks/blob/main/inference_kmer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8XyizGGzTgCp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D,Reshape, LSTM, Dropout, TimeDistributed, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "bases={'A':np.array([0,0,0,1]), 'C':np.array([0,0,1,0]), 'G':np.array([0,1,0,0]), 'T':np.array([1,0,0,0])}\n",
        "\n",
        "def Kmers_funct(seq, size):\n",
        "    return [seq[x:x+size].lower() for x in range(len(seq) - size + 1)]\n",
        "\n",
        "def one_hot_encode_2(y,num_classes):\n",
        "    y_encoded=[]\n",
        "    for value in y:\n",
        "\t    letter = [0 for _ in range(num_classes)]\n",
        "\t    letter[value] = 1\n",
        "\t    y_encoded.append(letter)\n",
        "    return np.array(y_encoded,dtype=np.float16)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N2A8S8tGTgCr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def selectref(el,pa,pc,pg,pt):\n",
        "\n",
        "  dicref={'U':['T'],\n",
        "  'R':['A','G'],\n",
        "  'Y':['C','T'],\n",
        "  'S':['G','C'],\n",
        "  'W':['A','T'],\n",
        "  'K':['G','T'],\n",
        "  'M':['A','C'],\n",
        "  'B':['C','G','T'],\n",
        "  'D':['A','G','T'],\n",
        "  'H':['A','C','T'],\n",
        "  'V':['A','C','G'],\n",
        "  'N':['A','T','G','C'],\n",
        "  }\n",
        "\n",
        "  dicprobs={'U':[1],\n",
        "  'R':[pa/(pa+pg),pg/(pa+pg)],\n",
        "  'Y':[pc/(pc+pt),pt/(pc+pt)],\n",
        "  'S':[pg/(pc+pg),pc/(pc+pg)],\n",
        "  'W':[pa/(pa+pt),pt/(pa+pt)],\n",
        "  'K':[pg/(pt+pg),pt/(pt+pg)],\n",
        "  'M':[pa/(pa+pc),pc/(pa+pc)],\n",
        "  'B':[pc/(pc+pg+pt),pg/(pc+pg+pt),pt/(pc+pg+pt)],\n",
        "  'D':[pa/(pa+pg+pt),pg/(pa+pg+pt),pt/(pa+pg+pt)],\n",
        "  'H':[pa/(pc+pa+pt),pc/(pc+pa+pt),pt/(pc+pa+pt)],\n",
        "  'V':[pa/(pc+pg+pa),pc/(pc+pg+pa),pg/(pc+pg+pa)],\n",
        "  'N':[pa/(pc+pg+pa+pt),pt/(pc+pg+pa+pt),pg/(pc+pg+pa+pt),pc/(pc+pg+pa+pt)]}\n",
        "\n",
        "  # print(dicprobs[el])\n",
        "  \n",
        "  return np.random.choice(dicref[el],p=dicprobs[el])\n",
        "  # return np.random.choice(dicref[el],p=dicprobs[el])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DtrZJ09mjDrW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "dir1 = \"/home/alphabox0008/HAPL_KH/Anubhav/Metafiles/\"\n",
        "f=open(dir1+\"unique_elems.pkl\",\"rb\")\n",
        "# f=open(\"unique_elems.pkl\",\"rb\")\n",
        "unique_elems=pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f=open(dir1+\"/vocab.pkl\",\"rb\")\n",
        "vocab=pickle.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ry20MyU9VOaX"
      },
      "outputs": [],
      "source": [
        "id_to_genus={}\n",
        "\n",
        "for el in unique_elems.keys():\n",
        "  id_to_genus[unique_elems[el]]=el"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "99rFGB2JjO7o"
      },
      "outputs": [],
      "source": [
        "#Use if genus name present in fasta file\n",
        "# df=pd.DataFrame(columns=[\"ID\",\"Actual_Genus\",\"Predicted_Genus\"])\n",
        "\n",
        "import pandas as pd\n",
        "#Use if genus name not present in fasta file\n",
        "df=pd.DataFrame(columns=[\"ID\",\"Description\",\"Predicted_Genus\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joff9qRRkLgw",
        "outputId": "54f598bd-9c6c-458c-e0c0-b012b4279858"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !pip install BioPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GLq765UoTgCs"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import time\n",
        "from Bio import SeqIO\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "cv.fit_transform(vocab)\n",
        "all_sequences=[]\n",
        "pathseq = \"/home/alphabox0008/HAPL_KH/Anubhav/Kmer Approach/Test/silva10seq.fasta\"\n",
        "for sequence in SeqIO.parse(pathseq, \"fasta\"):\n",
        "    # unique_elems[sequence.description.split()[1]]=0\n",
        "    seq=\"\"\n",
        "\n",
        "    id=sequence.id\n",
        "    # description\n",
        "\n",
        "    #Use if genus name present in fasta file\n",
        "    dftemp={\"ID\":id,\"Description\":str(sequence.description),\"Predicted_Genus\":\"\"}\n",
        "\n",
        "    #Use if genus name not present in fasta file\n",
        "    # dftemp={\"ID\":id,\"Predicted_Genus\":\"\"}\n",
        "    # df.loc[len(df.index)] = [id, \" \"] \n",
        "    df=df.append(dftemp,ignore_index=True)\n",
        "    \n",
        "\n",
        "    base_count=dict()\n",
        "    base_count['A']=0\n",
        "    base_count['C']=0\n",
        "    base_count['G']=0\n",
        "    base_count['T']=0\n",
        "    base_count['others']=0\n",
        "\n",
        "    for el in sequence.seq:\n",
        "      if el not in base_count.keys():\n",
        "\n",
        "        base_count['others']+=1\n",
        "      else:\n",
        "        base_count[el]+=1\n",
        "    \n",
        "    na=base_count['A']\n",
        "    nc=base_count['C']\n",
        "    ng=base_count['G']\n",
        "    nt=base_count['T']\n",
        "\n",
        "    pa=float(na/(na+nc+ng+nt))\n",
        "    pc=float(nc/(na+nc+ng+nt))\n",
        "    pg=float(ng/(na+nc+ng+nt))\n",
        "    pt=float(nt/(na+nc+ng+nt))\n",
        "\n",
        "    \n",
        "    for el in sequence.seq:\n",
        "      if el not in base_count.keys():\n",
        "\n",
        "        seq += (selectref(el,pa,pc,pg,pt))\n",
        "      else:\n",
        "        seq+=el\n",
        "    \n",
        "    words = Kmers_funct(seq, size=6)\n",
        "    joined_sentence = ' '.join(words)\n",
        "    all_sequences.append(joined_sentence)\n",
        "\n",
        "X=cv.transform(all_sequences).toarray()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5wSb6LX4ggp",
        "outputId": "f03f7ac9-ee7b-4092-da0a-25c39fef9658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EyKpX2L3TgCt"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "x_data=[]\n",
        "\n",
        "i=0\n",
        "for sequence in SeqIO.parse(pathseq, \"fasta\"):\n",
        "    x_data.append(X[i])\n",
        "    i+=1\n",
        "\n",
        "x_data=np.array(x_data,dtype=np.float32)\n",
        "x_data=np.reshape(x_data,(-1,4096,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpgvyARzTgCv",
        "outputId": "b0843e5a-0b71-4745-9d7d-0ad2a6578501"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 4091, 6)           42        \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4086, 3)           111       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12258)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              12553216  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4283)              4390075   \n",
            "=================================================================\n",
            "Total params: 16,943,444\n",
            "Trainable params: 16,943,444\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-17 16:52:12.450132: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-02-17 16:52:12.451348: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model=Sequential()\n",
        "model.add((Conv1D(input_shape=(4096,1),filters=6, kernel_size=6, activation='relu')))\n",
        "model.add((Conv1D(filters=3, kernel_size=6, activation='relu')))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024,activation='relu'))\n",
        "model.add(Dense(units=4283, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.load_weights(\"/home/alphabox0008/HAPL_KH/Anubhav/Kmer Approach/metafiles/005/cp-0005\")\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=2, mode='min')\n",
        "model.build()\n",
        "model.summary()\n",
        "# history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data= (x_test,y_test),callbacks=[cp_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mAdxzGQVYKjF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-02-17 16:52:25.963025: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "preds=model.predict(x_data)\n",
        "\n",
        "y_pred_labels=[np.argmax(el) for el in preds]\n",
        "\n",
        "i=0\n",
        "for index, row in df.iterrows():\n",
        "  # print(i)\n",
        "  row[\"Predicted_Genus\"]=id_to_genus[y_pred_labels[i]]\n",
        "  i+=1\n",
        "\n",
        "\n",
        "df.to_csv('all_predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "170"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_labels[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                           ID  \\\n",
            "0  AWPA01000003.163001.164539   \n",
            "1    CP028140.1270990.1272545   \n",
            "2        CP031770.82247.83802   \n",
            "3        ATXR01000029.87.1300   \n",
            "4    CP031770.1383248.1384803   \n",
            "5    CP028140.1520440.1521995   \n",
            "6        CP029694.17066.18621   \n",
            "7      CP029694.256072.257627   \n",
            "8        CP029694.23068.24623   \n",
            "9        CP029694.80044.81599   \n",
            "\n",
            "                                         Description Predicted_Genus  \n",
            "0  AWPA01000003.163001.164539 Bacteria;Firmicutes...   Streptococcus  \n",
            "1  CP028140.1270990.1272545 Bacteria;Firmicutes;B...   Streptococcus  \n",
            "2  CP031770.82247.83802 Bacteria;Firmicutes;Bacil...   Streptococcus  \n",
            "3  ATXR01000029.87.1300 Bacteria;Firmicutes;Bacil...   Streptococcus  \n",
            "4  CP031770.1383248.1384803 Bacteria;Firmicutes;B...   Streptococcus  \n",
            "5  CP028140.1520440.1521995 Bacteria;Firmicutes;B...   Streptococcus  \n",
            "6  CP029694.17066.18621 Bacteria;Firmicutes;Bacil...   Streptococcus  \n",
            "7  CP029694.256072.257627 Bacteria;Firmicutes;Bac...   Streptococcus  \n",
            "8  CP029694.23068.24623 Bacteria;Firmicutes;Bacil...   Streptococcus  \n",
            "9  CP029694.80044.81599 Bacteria;Firmicutes;Bacil...   Streptococcus  \n"
          ]
        }
      ],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "nIZxhk3ZYmOh",
        "outputId": "775adac8-d439-4c9d-f51e-c81e989d01f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
            "Empty DataFrame\n",
            "Columns: [ID, Actual_Genus, Predicted_Genus]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# df_misclassified=pd.DataFrame(columns=[\"ID\",\"Actual_Genus\",\"Predicted_Genus\"])\n",
        "\n",
        "# i=0\n",
        "# for index, row in df.iterrows():\n",
        "#   if row[\"Predicted_Genus\"] != row[\"Actual_Genus\"]:\n",
        "#     df_misclassified.append(row)\n",
        "# print(df_misclassified)\n",
        "# df_misclassified.to_csv('misclassified.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3PNAaRsWokI"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import roc_curve,auc\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# fpr = {}\n",
        "# tpr = {}\n",
        "# thresh ={}\n",
        "# roc_auc={}\n",
        "# n_class = lm\n",
        "# # y_true=np.array(y_true)\n",
        "# preds_training_data=model.predict(x_test)\n",
        "# # print(preds[0:3])\n",
        "# # print(y_test[0:3])\n",
        "\n",
        "# for i in range(n_class):\n",
        "#   # print(y_train[:,i])\n",
        "\n",
        "#   if len(np.unique(y_test[:,i]))==2:\n",
        "#     fpr[i], tpr[i], thresh[i] = roc_curve(y_test[:,i], preds[:,i])\n",
        "#     roc_auc[i] = auc(fpr[i], tpr[i])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "inference_kmer.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8eda46fcdaf684ca6c615bf0acdae196e42139c0edab1eb57e328e85edfac349"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('genomics': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
