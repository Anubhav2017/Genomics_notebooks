{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anubhav2017/Genomics_notebooks/blob/main/inference_kmer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XyizGGzTgCp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D,Reshape, LSTM, Dropout, TimeDistributed, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "bases={'A':np.array([0,0,0,1]), 'C':np.array([0,0,1,0]), 'G':np.array([0,1,0,0]), 'T':np.array([1,0,0,0])}\n",
        "\n",
        "def Kmers_funct(seq, size):\n",
        "    return [seq[x:x+size].lower() for x in range(len(seq) - size + 1)]\n",
        "\n",
        "def one_hot_encode_2(y,num_classes):\n",
        "    y_encoded=[]\n",
        "    for value in y:\n",
        "\t    letter = [0 for _ in range(num_classes)]\n",
        "\t    letter[value] = 1\n",
        "\t    y_encoded.append(letter)\n",
        "    return np.array(y_encoded,dtype=np.float16)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "N2A8S8tGTgCr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def selectref(el,pa,pc,pg,pt):\n",
        "\n",
        "  dicref={'U':['T'],\n",
        "  'R':['A','G'],\n",
        "  'Y':['C','T'],\n",
        "  'S':['G','C'],\n",
        "  'W':['A','T'],\n",
        "  'K':['G','T'],\n",
        "  'M':['A','C'],\n",
        "  'B':['C','G','T'],\n",
        "  'D':['A','G','T'],\n",
        "  'H':['A','C','T'],\n",
        "  'V':['A','C','G'],\n",
        "  'N':['A','T','G','C'],\n",
        "  }\n",
        "\n",
        "  dicprobs={'U':[1],\n",
        "  'R':[pa/(pa+pg),pg/(pa+pg)],\n",
        "  'Y':[pc/(pc+pt),pt/(pc+pt)],\n",
        "  'S':[pg/(pc+pg),pc/(pc+pg)],\n",
        "  'W':[pa/(pa+pt),pt/(pa+pt)],\n",
        "  'K':[pg/(pt+pg),pt/(pt+pg)],\n",
        "  'M':[pa/(pa+pc),pc/(pa+pc)],\n",
        "  'B':[pc/(pc+pg+pt),pg/(pc+pg+pt),pt/(pc+pg+pt)],\n",
        "  'D':[pa/(pa+pg+pt),pg/(pa+pg+pt),pt/(pa+pg+pt)],\n",
        "  'H':[pa/(pc+pa+pt),pc/(pc+pa+pt),pt/(pc+pa+pt)],\n",
        "  'V':[pa/(pc+pg+pa),pc/(pc+pg+pa),pg/(pc+pg+pa)],\n",
        "  'N':[pa/(pc+pg+pa+pt),pt/(pc+pg+pa+pt),pg/(pc+pg+pa+pt),pc/(pc+pg+pa+pt)]}\n",
        "\n",
        "  # print(dicprobs[el])\n",
        "  \n",
        "  return np.random.choice(dicref[el],p=dicprobs[el])\n",
        "  # return np.random.choice(dicref[el],p=dicprobs[el])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "f=open(\"unique_elems.pkl\",\"rb\")\n",
        "unique_elems=pickle.load(f)"
      ],
      "metadata": {
        "id": "DtrZJ09mjDrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_to_genus={}\n",
        "\n",
        "for el in unique_elems.keys():\n",
        "  id_to_genus[unique_elems[el]]=el"
      ],
      "metadata": {
        "id": "Ry20MyU9VOaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(columns=[\"ID\",\"Actual_Genus\",\"Predicted_Genus\"])\n"
      ],
      "metadata": {
        "id": "99rFGB2JjO7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joff9qRRkLgw",
        "outputId": "d8515879-09e4-4621-eaa3-fca4cb63d9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting BioPython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 28.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BioPython) (1.21.5)\n",
            "Installing collected packages: BioPython\n",
            "Successfully installed BioPython-1.79\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install BioPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLq765UoTgCs",
        "outputId": "3f9dcc76-2deb-476e-81cf-3e5f14c9a8ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24855, 4096)\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "import time\n",
        "from Bio import SeqIO\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "\n",
        "all_sequences=[]\n",
        "\n",
        "for sequence in SeqIO.parse('/content/drive/My Drive/ncbi_16s_18s_merged.fasta', \"fasta\"):\n",
        "    # unique_elems[sequence.description.split()[1]]=0\n",
        "    seq=\"\"\n",
        "\n",
        "    id=sequence.id\n",
        "\n",
        "    #Use if genus name present in fasta file\n",
        "    # dftemp={\"ID\":id,\"Actual_Genus\":str(sequence.description.split()[1]),\"Predicted_Genus\":\"\"}\n",
        "\n",
        "    #Use if genus name not present in fasta file\n",
        "    dftemp={\"ID\":id,\"Predicted_Genus\":\"\"}\n",
        "\n",
        "    df.append(dftemp,ignore_index=True)\n",
        "\n",
        "    base_count=dict()\n",
        "    base_count['A']=0\n",
        "    base_count['C']=0\n",
        "    base_count['G']=0\n",
        "    base_count['T']=0\n",
        "    base_count['others']=0\n",
        "\n",
        "    for el in sequence.seq:\n",
        "      if el not in base_count.keys():\n",
        "\n",
        "        base_count['others']+=1\n",
        "      else:\n",
        "        base_count[el]+=1\n",
        "    \n",
        "    na=base_count['A']\n",
        "    nc=base_count['C']\n",
        "    ng=base_count['G']\n",
        "    nt=base_count['T']\n",
        "\n",
        "    pa=float(na/(na+nc+ng+nt))\n",
        "    pc=float(nc/(na+nc+ng+nt))\n",
        "    pg=float(ng/(na+nc+ng+nt))\n",
        "    pt=float(nt/(na+nc+ng+nt))\n",
        "\n",
        "    \n",
        "    for el in sequence.seq:\n",
        "      if el not in base_count.keys():\n",
        "\n",
        "        seq += (selectref(el,pa,pc,pg,pt))\n",
        "      else:\n",
        "        seq+=el\n",
        "    \n",
        "    words = Kmers_funct(seq, size=6)\n",
        "    joined_sentence = ' '.join(words)\n",
        "    all_sequences.append(joined_sentence)\n",
        "\n",
        "X=cv.fit_transform(all_sequences).toarray()\n",
        "\n",
        "print(X.shape)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyKpX2L3TgCt"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "x_data=[]\n",
        "\n",
        "i=0\n",
        "for sequence in SeqIO.parse('/content/drive/My Drive/ncbi_16s_18s_merged.fasta', \"fasta\"):\n",
        "    x_data.append(X[i])\n",
        "    i+=1\n",
        "\n",
        "x_data=np.array(x_data,dtype=np.float32)\n",
        "x_data=np.reshape(x_data,(-1,4096,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpgvyARzTgCv",
        "outputId": "dcfe1869-afef-407c-96c9-76ce97664436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_12 (Conv1D)          (None, 4091, 6)           42        \n",
            "                                                                 \n",
            " conv1d_13 (Conv1D)          (None, 4086, 3)           111       \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 12258)             0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1024)              12553216  \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4283)              4390075   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,943,444\n",
            "Trainable params: 16,943,444\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model=Sequential()\n",
        "model.add((Conv1D(input_shape=(4096,1),filters=6, kernel_size=6, activation='relu')))\n",
        "model.add((Conv1D(filters=3, kernel_size=6, activation='relu')))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=1024,activation='relu'))\n",
        "model.add(Dense(units=4283, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.load_weights(\"/content/drive/My Drive/training_genomics_kmer/010/cp-0010\")\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=2, mode='min')\n",
        "model.build()\n",
        "model.summary()\n",
        "# history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data= (x_test,y_test),callbacks=[cp_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAdxzGQVYKjF"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "preds=model.predict(x_data)\n",
        "\n",
        "y_pred_labels=[np.argmax(el) for el in preds]\n",
        "\n",
        "i=0\n",
        "for index, row in df.iterrows():\n",
        "  row[\"Predicted_Genus\"]=id_to_genus[y_pred_labels[i]]\n",
        "  i+=1\n",
        "\n",
        "\n",
        "df.to_csv('all_predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_misclassified=pd.DataFrame(columns=[\"ID\",\"Actual_Genus\",\"Predicted_Genus\"])\n",
        "\n",
        "i=0\n",
        "for index, row in df.iterrows():\n",
        "  if row[\"Predicted_Genus\"] != row[\"Actual_Genus\"]:\n",
        "    df_misclassified.append(row)\n",
        "\n",
        "df_misclassified.to_csv('misclassified.csv')"
      ],
      "metadata": {
        "id": "nIZxhk3ZYmOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3PNAaRsWokI"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import roc_curve,auc\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# fpr = {}\n",
        "# tpr = {}\n",
        "# thresh ={}\n",
        "# roc_auc={}\n",
        "# n_class = lm\n",
        "# # y_true=np.array(y_true)\n",
        "# preds_training_data=model.predict(x_train)\n",
        "# # print(preds[0:3])\n",
        "# # print(y_test[0:3])\n",
        "\n",
        "# for i in range(n_class):\n",
        "#   # print(y_train[:,i])\n",
        "\n",
        "#   if len(np.unique(y_test[:,i]))==2:\n",
        "#     fpr[i], tpr[i], thresh[i] = roc_curve(y_test[:,i], preds[:,i])\n",
        "#     roc_auc[i] = auc(fpr[i], tpr[i])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "inference_kmer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "8eda46fcdaf684ca6c615bf0acdae196e42139c0edab1eb57e328e85edfac349"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('genomics': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}